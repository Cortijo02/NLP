{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2jLpZhWxc4wV"
   },
   "outputs": [],
   "source": [
    "#!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ijaKWX_ecbac",
    "outputId": "8d5bcab8-8fae-4119-bc00-535d4ef89622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, roc_auc_score\n",
    "from datasets import DatasetDict\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configuración de dispositivo (GPU o CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "q_zVgjhtcbae"
   },
   "outputs": [],
   "source": [
    "# @title Customize your key variables here\n",
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200 # @param {type:\"integer\"}\n",
    "TRAIN_BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "VALID_BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "EPOCHS = 1 # @param {type:\"integer\"}\n",
    "LEARNING_RATE = 1e-4 # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGICgd8wcbae",
    "outputId": "21ca6e93-8db1-4ba7-cf32-983174f34156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machines_files = glob('./data/machine/*.jsonl')\n",
    "len(machines_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id\n",
       "0     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "1     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "2     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "3     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "4     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "...                                                 ...\n",
       "1082  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1083  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1084  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1085  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1086  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "\n",
       "[1087 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids = pd.read_json('./data/human.jsonl', lines=True)\n",
    "df_ids = df_ids[['id']]\n",
    "df_ids[\"id\"] = df_ids[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rsuB0RLcbaf",
    "outputId": "0bd62678-67bf-4312-afc8-c55b042f648f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 1), (218, 1), (109, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_df, temp_df = train_test_split(df_ids, test_size=0.3, random_state=42)\n",
    "val_ids_df, test_ids_df = train_test_split(temp_df, test_size=1/3, random_state=42)\n",
    "\n",
    "train_ids_df.shape, val_ids_df.shape, test_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "Ouq8Ii2lcbae",
    "outputId": "b671c7f6-9177-437f-846f-9e51effa9b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_human</th>\n",
       "      <th>target_machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Long Island Surf Shop Owner Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Surf Shop Owner in Hometown Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Kind-Hearted Sou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Super Kind-Heart...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  \\\n",
       "0      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "1      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "2      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "3      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "4      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "...                                                  ...   \n",
       "14126  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14127  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14128  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14129  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14130  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "\n",
       "                                                  text_1  \\\n",
       "0      Inaugural Address by President Joseph R. Biden...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Inaugural Address by President Joseph R. Biden...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14126  Gabby Petito case: Surf shop owner in her home...   \n",
       "14127  Gabby Petito case: Surf shop owner in her home...   \n",
       "14128  Gabby Petito case: Surf shop owner in her home...   \n",
       "14129  Gabby Petito case: Surf shop owner in her home...   \n",
       "14130  Gabby Petito case: Surf shop owner in her home...   \n",
       "\n",
       "                                                  text_2  target_human  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...             1   \n",
       "1      What should be the focus of the speech? The In...             1   \n",
       "2      Biden's Inaugural Address Highlights Triumph o...             1   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...             1   \n",
       "4      President Biden Emphasizes Unity, Democracy, a...             1   \n",
       "...                                                  ...           ...   \n",
       "14126  Gabby Petito: Long Island Surf Shop Owner Reme...             1   \n",
       "14127  Gabby Petito: Surf Shop Owner in Hometown Reme...             1   \n",
       "14128  Gabby Petito Remembered as a 'Kind-Hearted Sou...             1   \n",
       "14129  Gabby Petito Remembered as a 'Super Kind-Heart...             1   \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...             1   \n",
       "\n",
       "       target_machine  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "14126               0  \n",
       "14127               0  \n",
       "14128               0  \n",
       "14129               0  \n",
       "14130               0  \n",
       "\n",
       "[14131 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human = pd.read_json('./data/human.jsonl', lines=True)\n",
    "\n",
    "df_machine = pd.read_json(machines_files[0], lines=True)\n",
    "for file in machines_files[1:]:\n",
    "    df_current = pd.read_json(file, lines=True)\n",
    "    df_machine = pd.concat([df_machine, df_current])\n",
    "\n",
    "\n",
    "df_human[\"id\"] = df_human[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "df_machine[\"id\"] = df_machine[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "\n",
    "df_combined = pd.merge(df_human, df_machine, on=\"id\", suffixes=(\"_1\", \"_2\"))\n",
    "df_combined['target_human'] = 1\n",
    "df_combined['target_machine'] = 0\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "CB8z35Ggcbae",
    "outputId": "d0dccaae-b1db-4720-c8ba-f2f24ab40231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_human</th>\n",
       "      <th>target_machine</th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito: Long Island Surf Shop Owner Reme...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Surf Shop Owner in Hometown Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Kind-Hearted Sou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Super Kind-Heart...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  \\\n",
       "0      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "1      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "2      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "3      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "4      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "...                                                  ...   \n",
       "14126  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14127  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14128  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14129  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14130  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "\n",
       "                                                  text_1  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14126  Gabby Petito: Long Island Surf Shop Owner Reme...   \n",
       "14127  Gabby Petito case: Surf shop owner in her home...   \n",
       "14128  Gabby Petito case: Surf shop owner in her home...   \n",
       "14129  Gabby Petito Remembered as a 'Super Kind-Heart...   \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...   \n",
       "\n",
       "                                                  text_2  target_human  \\\n",
       "0      Inaugural Address by President Joseph R. Biden...             0   \n",
       "1      What should be the focus of the speech? The In...             1   \n",
       "2      Biden's Inaugural Address Highlights Triumph o...             1   \n",
       "3      Inaugural Address by President Joseph R. Biden...             0   \n",
       "4      President Biden Emphasizes Unity, Democracy, a...             1   \n",
       "...                                                  ...           ...   \n",
       "14126  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "14127  Gabby Petito: Surf Shop Owner in Hometown Reme...             1   \n",
       "14128  Gabby Petito Remembered as a 'Kind-Hearted Sou...             1   \n",
       "14129  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "14130  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "\n",
       "       target_machine target_tuple  \n",
       "0                   1       (0, 1)  \n",
       "1                   0       (1, 0)  \n",
       "2                   0       (1, 0)  \n",
       "3                   1       (0, 1)  \n",
       "4                   0       (1, 0)  \n",
       "...               ...          ...  \n",
       "14126               1       (0, 1)  \n",
       "14127               0       (1, 0)  \n",
       "14128               0       (1, 0)  \n",
       "14129               1       (0, 1)  \n",
       "14130               1       (0, 1)  \n",
       "\n",
       "[14131 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = df_combined.sample(frac=0.5, random_state=42).index\n",
    "df_combined.loc[random_indices, ['text_1', 'text_2']] = df_combined.loc[random_indices, ['text_2', 'text_1']].values\n",
    "df_combined.loc[random_indices, ['target_human']] = 0\n",
    "df_combined.loc[random_indices, ['target_machine']] = 1\n",
    "df_combined['target_tuple'] = list(zip(df_combined['target_human'], df_combined['target_machine']))\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9880, 3), (2834, 3), (1417, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_combined[df_combined['id'].isin(train_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "X_val = df_combined[df_combined['id'].isin(val_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "X_test = df_combined[df_combined['id'].isin(test_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>UK sees very credible threat of imminent IS Ka...</td>\n",
       "      <td>A suicide attack is imminent at Kabul airport,...</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>Prosecutors Adjust Duration of Time Derek Chau...</td>\n",
       "      <td>Prosecutors: Officer was on Floyd's neck for a...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>Violent Clashes Erupt in Baghdad Over Parliame...</td>\n",
       "      <td>Protests against Iraq election results turn vi...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>Who Spent Their Last Stimulus Checks?\\n\\nAs Pr...</td>\n",
       "      <td>Stimulus Checks: A Lifeline for Low-Income Fam...</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>Judge Dismisses Gun Possession Charge for Teen...</td>\n",
       "      <td>EXPLAINER: Why did judge drop Rittenhouse gun ...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text_1  \\\n",
       "6982   UK sees very credible threat of imminent IS Ka...   \n",
       "5306   Prosecutors Adjust Duration of Time Derek Chau...   \n",
       "2215   Violent Clashes Erupt in Baghdad Over Parliame...   \n",
       "10328  Who Spent Their Last Stimulus Checks?\\n\\nAs Pr...   \n",
       "8255   Judge Dismisses Gun Possession Charge for Teen...   \n",
       "\n",
       "                                                  text_2 target_tuple  \n",
       "6982   A suicide attack is imminent at Kabul airport,...       (1, 0)  \n",
       "5306   Prosecutors: Officer was on Floyd's neck for a...       (0, 1)  \n",
       "2215   Protests against Iraq election results turn vi...       (0, 1)  \n",
       "10328  Stimulus Checks: A Lifeline for Low-Income Fam...       (1, 0)  \n",
       "8255   EXPLAINER: Why did judge drop Rittenhouse gun ...       (0, 1)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9880,), (2834,), (1417,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = X_train['target_tuple']\n",
    "y_val = X_val['target_tuple']\n",
    "y_test = X_test['target_tuple']\n",
    "\n",
    "X_train = X_train.drop(columns=['target_tuple'])\n",
    "X_val = X_val.drop(columns=['target_tuple'])\n",
    "X_test = X_test.drop(columns=['target_tuple'])\n",
    "\n",
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>University of Wisconsin Oshkosh Student Claims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>TESLA STOCK SOARS ON Q3 EARNINGS REPORT\\n\\nWYO...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>WYOMING (WBAY) – A University of Wisconsin Osh...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>University of Wisconsin Oshkosh Student Claims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text_1  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14100  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "14101  TESLA STOCK SOARS ON Q3 EARNINGS REPORT\\n\\nWYO...   \n",
       "14102  WYOMING (WBAY) – A University of Wisconsin Osh...   \n",
       "14103  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "14104  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "\n",
       "                                                  text_2  \n",
       "0      Inaugural Address by President Joseph R. Biden...  \n",
       "1      What should be the focus of the speech? The In...  \n",
       "2      Biden's Inaugural Address Highlights Triumph o...  \n",
       "3      Inaugural Address by President Joseph R. Biden...  \n",
       "4      President Biden Emphasizes Unity, Democracy, a...  \n",
       "...                                                  ...  \n",
       "14100  University of Wisconsin Oshkosh Student Claims...  \n",
       "14101  Univ. of Wisconsin Oshkosh student helping Gab...  \n",
       "14102  Univ. of Wisconsin Oshkosh student helping Gab...  \n",
       "14103  University of Wisconsin Oshkosh Student Claims...  \n",
       "14104  McKenna's Lost Friend: Debunking the Evidence ...  \n",
       "\n",
       "[9880 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9880 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target_tuple\n",
       "0           (0, 1)\n",
       "1           (1, 0)\n",
       "2           (1, 0)\n",
       "3           (0, 1)\n",
       "4           (1, 0)\n",
       "...            ...\n",
       "14100       (1, 0)\n",
       "14101       (0, 1)\n",
       "14102       (0, 1)\n",
       "14103       (1, 0)\n",
       "14104       (1, 0)\n",
       "\n",
       "[9880 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LjuGLfavcbaf"
   },
   "outputs": [],
   "source": [
    "class AiClassificationDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Use iloc to access the rows by index for data and labels\n",
    "        text_1 = self.data.iloc[index]['text_1']\n",
    "        text_2 = self.data.iloc[index]['text_2']\n",
    "        target = self.labels.iloc[index]  # assuming labels are in a compatible format\n",
    "        return {\n",
    "            'text_1': text_1,\n",
    "            'text_2': text_2,\n",
    "            'targets': target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3U3xQ8HPcbaf"
   },
   "outputs": [],
   "source": [
    "class AiClassificationCollator:\n",
    "    def __init__(self, dataset, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataset\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, input_batch):\n",
    "        batch_dict = {colname: [x[colname] for x in input_batch] for colname in input_batch[0]}\n",
    "\n",
    "        comment_text_1 = batch_dict['text_1']\n",
    "        comment_text_2 = batch_dict['text_2']\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            comment_text_1,\n",
    "            comment_text_2,\n",
    "            max_length=self.max_len,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs['token_type_ids'], dtype=torch.long),\n",
    "            'targets': torch.tensor(batch_dict['targets'], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8V7aggMfcbaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexg\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alexg\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "qXmpQsNzcbaf"
   },
   "outputs": [],
   "source": [
    "training_set = AiClassificationDataset(X_train, y_train)\n",
    "validation_set = AiClassificationDataset(X_val, y_val)\n",
    "test_set = AiClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(training_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(validation_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(test_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **val_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "KCmZiciwcbaf"
   },
   "outputs": [],
   "source": [
    "class TransformerClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('google-bert/bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 256)\n",
    "        self.l4 = torch.nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        last_hidden_state = self.l1(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        ).last_hidden_state\n",
    "\n",
    "        last_hidden_state = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids).last_hidden_state\n",
    "        cls_token = last_hidden_state[:, 0]\n",
    "        hidden_output = F.gelu(self.l3(self.l2(cls_token)))\n",
    "        output = self.l4(hidden_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EsVknC-0eJPY"
   },
   "outputs": [],
   "source": [
    "def training_step(input_ids, attention_mask, token_type_ids, y, model, optimizer):\n",
    "    logits = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y, reduction='mean')\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ypAtTnOtcbag"
   },
   "outputs": [],
   "source": [
    "model = TransformerClass()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QvHAB-s6cbag"
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            input_ids = data['ids'].to(device)\n",
    "            attention_mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            val_loss += torch.nn.functional.cross_entropy(logits, targets, reduction='sum').item()  # Accumulate validation loss\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (preds == targets.argmax(dim=1)).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / total_predictions\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ClviN54hFd6",
    "outputId": "fa97052b-3582-43bc-a74e-e37e5d035441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Step 1/618\n",
      "  Running Loss: 0.6789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m---> 39\u001b[0m     train(epoch)\n",
      "Cell \u001b[1;32mIn [49], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, log_interval, save_model_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn [46], line 5\u001b[0m, in \u001b[0;36mtraining_step\u001b[1;34m(input_ids, attention_mask, token_type_ids, y, model, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask, token_type_ids)\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch, log_interval=200, save_model_path='./model_weights'):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for step, data in enumerate(training_loader):\n",
    "        input_ids = data['ids'].to(device)\n",
    "        attention_mask = data['mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)\n",
    "        targets = data['targets'].to(device)\n",
    "\n",
    "        loss = training_step(input_ids, attention_mask, token_type_ids, targets, model, optimizer)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            avg_loss = running_loss / (step + 1)\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}, Step {step + 1}/{len(training_loader)}\")\n",
    "            print(f\"  Running Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    avg_train_loss = running_loss / len(training_loader)\n",
    "\n",
    "    avg_val_loss, val_accuracy = validate()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS} - End of epoch\")\n",
    "    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        if not os.path.exists(save_model_path):\n",
    "            os.makedirs(save_model_path)\n",
    "\n",
    "        model_save_path = os.path.join(save_model_path, f\"model_epoch_{epoch + 1}_acc{best_accuracy:.4f}.pth\")\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEfPdV-xkBYY",
    "outputId": "b3936e5f-1a3f-4184-b3fc-e3e7079bc71b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-dbb2572894c5>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (l4): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerClass()\n",
    "\n",
    "model_save_path = './model_weights/model_epoch_1.pth'\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eavl0eh5j1f0",
    "outputId": "1146832a-8f39-4ce5-8b87-4306d7ea1560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0311\n",
      "Test Accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            input_ids = data['ids'].to(device)\n",
    "            attention_mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            test_loss += torch.nn.functional.cross_entropy(logits, targets, reduction='sum').item()\n",
    "\n",
    "            # Predicciones\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (preds == targets.argmax(dim=1)).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / total_predictions\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = test(test_loader, model, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
