{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2jLpZhWxc4wV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\alexg\\miniconda3\\envs\\gpu_env\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install datasets\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ijaKWX_ecbac",
    "outputId": "8d5bcab8-8fae-4119-bc00-535d4ef89622"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexg\\miniconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\alexg\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\alexg\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, roc_auc_score\n",
    "from datasets import DatasetDict\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configuración de dispositivo (GPU o CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q_zVgjhtcbae"
   },
   "outputs": [],
   "source": [
    "# @title Customize your key variables here\n",
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512 # @param {type:\"integer\"}\n",
    "TRAIN_BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "VALID_BATCH_SIZE = 16 # @param {type:\"integer\"}\n",
    "EPOCHS = 1 # @param {type:\"integer\"}\n",
    "LEARNING_RATE = 1e-4 # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGICgd8wcbae",
    "outputId": "21ca6e93-8db1-4ba7-cf32-983174f34156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machines_files = glob('../data/machine/*.jsonl')\n",
    "len(machines_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id\n",
       "0     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "1     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "2     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "3     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "4     news-2021-01-01-2021-12-31-bideninauguration/a...\n",
       "...                                                 ...\n",
       "1082  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1083  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1084  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1085  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "1086  news-2021-01-01-2021-12-31-wyominggabbypetito/...\n",
       "\n",
       "[1087 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ids = pd.read_json('../data/human.jsonl', lines=True)\n",
    "df_ids = df_ids[['id']]\n",
    "df_ids[\"id\"] = df_ids[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rsuB0RLcbaf",
    "outputId": "0bd62678-67bf-4312-afc8-c55b042f648f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 1), (218, 1), (109, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_df, temp_df = train_test_split(df_ids, test_size=0.3, random_state=42)\n",
    "val_ids_df, test_ids_df = train_test_split(temp_df, test_size=1/3, random_state=42)\n",
    "\n",
    "train_ids_df.shape, val_ids_df.shape, test_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "Ouq8Ii2lcbae",
    "outputId": "b671c7f6-9177-437f-846f-9e51effa9b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_human</th>\n",
       "      <th>target_machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Long Island Surf Shop Owner Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Surf Shop Owner in Hometown Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Kind-Hearted Sou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Super Kind-Heart...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  \\\n",
       "0      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "1      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "2      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "3      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "4      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "...                                                  ...   \n",
       "14126  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14127  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14128  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14129  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14130  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "\n",
       "                                                  text_1  \\\n",
       "0      Inaugural Address by President Joseph R. Biden...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Inaugural Address by President Joseph R. Biden...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14126  Gabby Petito case: Surf shop owner in her home...   \n",
       "14127  Gabby Petito case: Surf shop owner in her home...   \n",
       "14128  Gabby Petito case: Surf shop owner in her home...   \n",
       "14129  Gabby Petito case: Surf shop owner in her home...   \n",
       "14130  Gabby Petito case: Surf shop owner in her home...   \n",
       "\n",
       "                                                  text_2  target_human  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...             1   \n",
       "1      What should be the focus of the speech? The In...             1   \n",
       "2      Biden's Inaugural Address Highlights Triumph o...             1   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...             1   \n",
       "4      President Biden Emphasizes Unity, Democracy, a...             1   \n",
       "...                                                  ...           ...   \n",
       "14126  Gabby Petito: Long Island Surf Shop Owner Reme...             1   \n",
       "14127  Gabby Petito: Surf Shop Owner in Hometown Reme...             1   \n",
       "14128  Gabby Petito Remembered as a 'Kind-Hearted Sou...             1   \n",
       "14129  Gabby Petito Remembered as a 'Super Kind-Heart...             1   \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...             1   \n",
       "\n",
       "       target_machine  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "14126               0  \n",
       "14127               0  \n",
       "14128               0  \n",
       "14129               0  \n",
       "14130               0  \n",
       "\n",
       "[14131 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human = pd.read_json('../data/human.jsonl', lines=True)\n",
    "\n",
    "df_machine = pd.read_json(machines_files[0], lines=True)\n",
    "for file in machines_files[1:]:\n",
    "    df_current = pd.read_json(file, lines=True)\n",
    "    df_machine = pd.concat([df_machine, df_current])\n",
    "\n",
    "\n",
    "df_human[\"id\"] = df_human[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "df_machine[\"id\"] = df_machine[\"id\"].str.split('/').str[1:].str.join('/')\n",
    "\n",
    "df_combined = pd.merge(df_human, df_machine, on=\"id\", suffixes=(\"_1\", \"_2\"))\n",
    "df_combined['target_human'] = 1\n",
    "df_combined['target_machine'] = 0\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "CB8z35Ggcbae",
    "outputId": "d0dccaae-b1db-4720-c8ba-f2f24ab40231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_human</th>\n",
       "      <th>target_machine</th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news-2021-01-01-2021-12-31-bideninauguration/a...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito: Long Island Surf Shop Owner Reme...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito: Surf Shop Owner in Hometown Reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Kind-Hearted Sou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>Gabby Petito Remembered as a 'Super Kind-Heart...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>news-2021-01-01-2021-12-31-wyominggabbypetito/...</td>\n",
       "      <td>A Very Kind and Sweet Woman in Long Island Sho...</td>\n",
       "      <td>Gabby Petito case: Surf shop owner in her home...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14131 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  \\\n",
       "0      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "1      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "2      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "3      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "4      news-2021-01-01-2021-12-31-bideninauguration/a...   \n",
       "...                                                  ...   \n",
       "14126  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14127  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14128  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14129  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "14130  news-2021-01-01-2021-12-31-wyominggabbypetito/...   \n",
       "\n",
       "                                                  text_1  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14126  Gabby Petito: Long Island Surf Shop Owner Reme...   \n",
       "14127  Gabby Petito case: Surf shop owner in her home...   \n",
       "14128  Gabby Petito case: Surf shop owner in her home...   \n",
       "14129  Gabby Petito Remembered as a 'Super Kind-Heart...   \n",
       "14130  A Very Kind and Sweet Woman in Long Island Sho...   \n",
       "\n",
       "                                                  text_2  target_human  \\\n",
       "0      Inaugural Address by President Joseph R. Biden...             0   \n",
       "1      What should be the focus of the speech? The In...             1   \n",
       "2      Biden's Inaugural Address Highlights Triumph o...             1   \n",
       "3      Inaugural Address by President Joseph R. Biden...             0   \n",
       "4      President Biden Emphasizes Unity, Democracy, a...             1   \n",
       "...                                                  ...           ...   \n",
       "14126  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "14127  Gabby Petito: Surf Shop Owner in Hometown Reme...             1   \n",
       "14128  Gabby Petito Remembered as a 'Kind-Hearted Sou...             1   \n",
       "14129  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "14130  Gabby Petito case: Surf shop owner in her home...             0   \n",
       "\n",
       "       target_machine target_tuple  \n",
       "0                   1       (0, 1)  \n",
       "1                   0       (1, 0)  \n",
       "2                   0       (1, 0)  \n",
       "3                   1       (0, 1)  \n",
       "4                   0       (1, 0)  \n",
       "...               ...          ...  \n",
       "14126               1       (0, 1)  \n",
       "14127               0       (1, 0)  \n",
       "14128               0       (1, 0)  \n",
       "14129               1       (0, 1)  \n",
       "14130               1       (0, 1)  \n",
       "\n",
       "[14131 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = df_combined.sample(frac=0.5, random_state=42).index\n",
    "df_combined.loc[random_indices, ['text_1', 'text_2']] = df_combined.loc[random_indices, ['text_2', 'text_1']].values\n",
    "df_combined.loc[random_indices, ['target_human']] = 0\n",
    "df_combined.loc[random_indices, ['target_machine']] = 1\n",
    "df_combined['target_tuple'] = list(zip(df_combined['target_human'], df_combined['target_machine']))\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9880, 3), (2834, 3), (1417, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_combined[df_combined['id'].isin(train_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "X_val = df_combined[df_combined['id'].isin(val_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "X_test = df_combined[df_combined['id'].isin(test_ids_df['id'])].drop(columns=['id', 'target_human', 'target_machine'])\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>Texas Winter Storm Unleashes Power Outages, Va...</td>\n",
       "      <td>Power cut across Texas as snow, ice blanket so...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>You're Not Getting a 4th Stimulus Check. Here'...</td>\n",
       "      <td>Federal Stimulus Checks Unlikely, States Step ...</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13893</th>\n",
       "      <td>The circular reckoning over 'missing white wom...</td>\n",
       "      <td>Chris Cuomo on Gabby Petito's Case and the Pro...</td>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>The closure of the US embassy in Kabul, Afghan...</td>\n",
       "      <td>US completes evacuation of embassy in Afghanis...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>A Brief Overview of the Benefits of a Double-C...</td>\n",
       "      <td>How effective is a single vaccine dose against...</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text_1  \\\n",
       "13510  Texas Winter Storm Unleashes Power Outages, Va...   \n",
       "10390  You're Not Getting a 4th Stimulus Check. Here'...   \n",
       "13893  The circular reckoning over 'missing white wom...   \n",
       "7333   The closure of the US embassy in Kabul, Afghan...   \n",
       "3691   A Brief Overview of the Benefits of a Double-C...   \n",
       "\n",
       "                                                  text_2 target_tuple  \n",
       "13510  Power cut across Texas as snow, ice blanket so...       (0, 1)  \n",
       "10390  Federal Stimulus Checks Unlikely, States Step ...       (1, 0)  \n",
       "13893  Chris Cuomo on Gabby Petito's Case and the Pro...       (1, 0)  \n",
       "7333   US completes evacuation of embassy in Afghanis...       (0, 1)  \n",
       "3691   How effective is a single vaccine dose against...       (0, 1)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9880,), (2834,), (1417,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = X_train['target_tuple']\n",
    "y_val = X_val['target_tuple']\n",
    "y_test = X_test['target_tuple']\n",
    "\n",
    "X_train = X_train.drop(columns=['target_tuple'])\n",
    "X_val = X_val.drop(columns=['target_tuple'])\n",
    "X_test = X_test.drop(columns=['target_tuple'])\n",
    "\n",
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural Address: President Joseph R. Biden J...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>What should be the focus of the speech? The In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>Biden's Inaugural Address Highlights Triumph o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden's Inaugural Address: A Clarion Call for ...</td>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inaugural Address by President Joseph R. Biden...</td>\n",
       "      <td>President Biden Emphasizes Unity, Democracy, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>University of Wisconsin Oshkosh Student Claims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>TESLA STOCK SOARS ON Q3 EARNINGS REPORT\\n\\nWYO...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>WYOMING (WBAY) – A University of Wisconsin Osh...</td>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>University of Wisconsin Oshkosh Student Claims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>Univ. of Wisconsin Oshkosh student helping Gab...</td>\n",
       "      <td>McKenna's Lost Friend: Debunking the Evidence ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text_1  \\\n",
       "0      Inaugural Address: President Joseph R. Biden J...   \n",
       "1      Inaugural Address by President Joseph R. Biden...   \n",
       "2      Inaugural Address by President Joseph R. Biden...   \n",
       "3      Biden's Inaugural Address: A Clarion Call for ...   \n",
       "4      Inaugural Address by President Joseph R. Biden...   \n",
       "...                                                  ...   \n",
       "14100  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "14101  TESLA STOCK SOARS ON Q3 EARNINGS REPORT\\n\\nWYO...   \n",
       "14102  WYOMING (WBAY) – A University of Wisconsin Osh...   \n",
       "14103  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "14104  Univ. of Wisconsin Oshkosh student helping Gab...   \n",
       "\n",
       "                                                  text_2  \n",
       "0      Inaugural Address by President Joseph R. Biden...  \n",
       "1      What should be the focus of the speech? The In...  \n",
       "2      Biden's Inaugural Address Highlights Triumph o...  \n",
       "3      Inaugural Address by President Joseph R. Biden...  \n",
       "4      President Biden Emphasizes Unity, Democracy, a...  \n",
       "...                                                  ...  \n",
       "14100  University of Wisconsin Oshkosh Student Claims...  \n",
       "14101  Univ. of Wisconsin Oshkosh student helping Gab...  \n",
       "14102  Univ. of Wisconsin Oshkosh student helping Gab...  \n",
       "14103  University of Wisconsin Oshkosh Student Claims...  \n",
       "14104  McKenna's Lost Friend: Debunking the Evidence ...  \n",
       "\n",
       "[9880 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14103</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>(1, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9880 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target_tuple\n",
       "0           (0, 1)\n",
       "1           (1, 0)\n",
       "2           (1, 0)\n",
       "3           (0, 1)\n",
       "4           (1, 0)\n",
       "...            ...\n",
       "14100       (1, 0)\n",
       "14101       (0, 1)\n",
       "14102       (0, 1)\n",
       "14103       (1, 0)\n",
       "14104       (1, 0)\n",
       "\n",
       "[9880 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LjuGLfavcbaf"
   },
   "outputs": [],
   "source": [
    "class AiClassificationDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text_1 = self.data.iloc[index]['text_1']\n",
    "        text_2 = self.data.iloc[index]['text_2']\n",
    "        target = self.labels.iloc[index] \n",
    "        return {\n",
    "            'text_1': text_1,\n",
    "            'text_2': text_2,\n",
    "            'targets': target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3U3xQ8HPcbaf"
   },
   "outputs": [],
   "source": [
    "class AiClassificationCollator:\n",
    "    def __init__(self, dataset, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataset\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, input_batch):\n",
    "        batch_dict = {colname: [x[colname] for x in input_batch] for colname in input_batch[0]}\n",
    "\n",
    "        comment_text_1 = batch_dict['text_1']\n",
    "        comment_text_2 = batch_dict['text_2']\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            comment_text_1,\n",
    "            comment_text_2,\n",
    "            max_length=self.max_len,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'targets': torch.tensor(batch_dict['targets'], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8V7aggMfcbaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qXmpQsNzcbaf"
   },
   "outputs": [],
   "source": [
    "training_set = AiClassificationDataset(X_train, y_train)\n",
    "validation_set = AiClassificationDataset(X_val, y_val)\n",
    "test_set = AiClassificationDataset(X_test, y_test)\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(training_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(validation_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': AiClassificationCollator(test_set, tokenizer, MAX_LEN)\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **val_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KCmZiciwcbaf"
   },
   "outputs": [],
   "source": [
    "class TransformerClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerClass, self).__init__()\n",
    "        self.l1 = T5EncoderModel.from_pretrained('t5-small')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        last_hidden_state = self.l1(input_ids=ids, attention_mask=mask).last_hidden_state\n",
    "        sentence_embedding = torch.sum(last_hidden_state*mask.unsqueeze(-1), 1) / torch.sum(mask.unsqueeze(-1),1)\n",
    "        output = self.classifier(sentence_embedding)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EsVknC-0eJPY"
   },
   "outputs": [],
   "source": [
    "def training_step(input_ids, attention_mask, y, model, optimizer):\n",
    "    logits = model(input_ids, attention_mask)\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y, reduction='mean')\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ypAtTnOtcbag"
   },
   "outputs": [],
   "source": [
    "model = TransformerClass()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QvHAB-s6cbag"
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            input_ids = data['ids'].to(device)\n",
    "            attention_mask = data['mask'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            val_loss += torch.nn.functional.cross_entropy(logits, targets, reduction='sum').item()  # Accumulate validation loss\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (preds == targets.argmax(dim=1)).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / total_predictions\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ClviN54hFd6",
    "outputId": "fa97052b-3582-43bc-a74e-e37e5d035441"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Step 1/618\n",
      "  Running Loss: 0.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m---> 38\u001b[0m     train(epoch)\n",
      "Cell \u001b[1;32mIn [22], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, log_interval, save_model_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn [19], line 5\u001b[0m, in \u001b[0;36mtraining_step\u001b[1;34m(input_ids, attention_mask, y, model, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask)\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch, log_interval=200, save_model_path='./model_weights'):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for step, data in enumerate(training_loader):\n",
    "        input_ids = data['ids'].to(device)\n",
    "        attention_mask = data['mask'].to(device)\n",
    "        targets = data['targets'].to(device)\n",
    "\n",
    "        loss = training_step(input_ids, attention_mask, targets, model, optimizer)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            avg_loss = running_loss / (step + 1)\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}, Step {step + 1}/{len(training_loader)}\")\n",
    "            print(f\"  Running Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    avg_train_loss = running_loss / len(training_loader)\n",
    "\n",
    "    avg_val_loss, val_accuracy = validate()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS} - End of epoch\")\n",
    "    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        if not os.path.exists(save_model_path):\n",
    "            os.makedirs(save_model_path)\n",
    "\n",
    "        model_save_path = os.path.join(save_model_path, f\"model_epoch_{epoch + 1}_acc{best_accuracy:.4f}.pth\")\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEfPdV-xkBYY",
    "outputId": "b3936e5f-1a3f-4184-b3fc-e3e7079bc71b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-dbb2572894c5>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (l4): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerClass()\n",
    "\n",
    "model_save_path = './model_weights/model_epoch_1.pth'\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eavl0eh5j1f0",
    "outputId": "1146832a-8f39-4ce5-8b87-4306d7ea1560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0311\n",
      "Test Accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            input_ids = data['ids'].to(device)\n",
    "            attention_mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            test_loss += torch.nn.functional.cross_entropy(logits, targets, reduction='sum').item()\n",
    "\n",
    "            # Predicciones\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (preds == targets.argmax(dim=1)).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / total_predictions\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = test(test_loader, model, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
